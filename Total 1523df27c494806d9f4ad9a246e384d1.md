# Total

![image.png](image.png)

![image.png](image%201.png)

![image.png](image%202.png)

![image.png](image%203.png)

![image.png](image%204.png)

![image.png](image%205.png)

![image.png](image%206.png)

**Entropy**

![image.png](image%207.png)

![image.png](image%208.png)

▶ Entropy of discrete distributions is non-negative

Entropy is additive for independent random variables.

![image.png](image%209.png)

![image.png](image%2010.png)

The goal of experiments is to reduce uncertainty about something.

• The value of a parameter, the best model for some dataset, etc

![image.png](image%2011.png)

![image.png](image%2012.png)

![image.png](image%2013.png)

![image.png](image%2014.png)

![image.png](image%2015.png)

![image.png](image%2016.png)

![image.png](image%2017.png)

![image.png](image%2018.png)

![image.png](image%2019.png)

![image.png](image%2020.png)

![image.png](image%2021.png)

**Entropy is the optimal bound of the entropy**

![image.png](image%2022.png)

**Symbol Coding**

### No free lunch theorem

![image.png](image%2023.png)

### Lossy and lossness compression

![image.png](image%2024.png)

![image.png](image%2025.png)

Even if the code is invertible, it might be hard to decode

![image.png](image%2026.png)

![image.png](image%2027.png)

It also hold for uniquely decodable code

![image.png](image%2028.png)

![image.png](image%2029.png)

![image.png](image%2030.png)

![image.png](image%2031.png)

![image.png](image%2032.png)

![image.png](image%2033.png)

![image.png](image%2034.png)

### KL divergence is a convex down function, so it have a localbal unique minimum

![image.png](image%2035.png)

![image.png](image%2036.png)

![image.png](image%2037.png)

![image.png](image%2038.png)

![image.png](image%2039.png)

![image.png](image%2040.png)

![image.png](image%2041.png)

**Mutual Information**

![image.png](image%2042.png)

![image.png](image%2043.png)

![image.png](image%2044.png)

![image.png](image%2045.png)

![image.png](image%2046.png)

![image.png](image%2047.png)

![image.png](image%2048.png)

![image.png](image%2049.png)

![image.png](image%2050.png)

![image.png](image%2051.png)

![image.png](image%2052.png)

![image.png](image%2053.png)

![image.png](image%2054.png)

![image.png](image%2055.png)

![image.png](image%2056.png)

![image.png](image%2057.png)

![image.png](image%2058.png)

![image.png](image%2059.png)

![image.png](image%2060.png)

![image.png](image%2061.png)

![image.png](image%2062.png)

![image.png](image%2063.png)

![image.png](image%2064.png)

![image.png](image%2065.png)

![image.png](image%2066.png)

**Channel Coding**

![image.png](image%2067.png)

![image.png](image%2068.png)

![image.png](image%2069.png)

![image.png](image%2070.png)

![image.png](image%2071.png)

each channel can only transmit one symble at one time (not the entire code word). p(s) means the probability of any speicific message.

![image.png](image%2072.png)

![image.png](image%2073.png)

![image.png](image%2074.png)

”Faster code” means higher transmission rate.

![image.png](image%2075.png)

![image.png](image%2076.png)

![image.png](image%2077.png)

![image.png](image%2078.png)

![image.png](image%2079.png)

![image.png](image%2080.png)

![image.png](image%2081.png)

![image.png](image%2082.png)

![image.png](image%2083.png)

**Probability Inference**

![image.png](image%2084.png)

![image.png](image%2085.png)

![image.png](image%2086.png)

![image.png](image%2087.png)

![image.png](image%2088.png)

power is like ability to not miss a discovery

![image.png](image%2089.png)

![image.png](image%2090.png)

![image.png](image%2091.png)

![image.png](image%2092.png)

![image.png](image%2093.png)

![image.png](image%2094.png)

![image.png](image%2095.png)

![image.png](image%2096.png)

![image.png](image%2097.png)

![image.png](image%2098.png)

**Bayesian Hypothesis Testing**

![image.png](image%2099.png)

![image.png](image%20100.png)

![image.png](image%20101.png)

![image.png](image%20102.png)

![image.png](image%20103.png)

![image.png](image%20104.png)

Estimating Information

![image.png](image%20105.png)

![image.png](image%20106.png)

![image.png](image%20107.png)

![image.png](image%20108.png)

Apply to discrete data

![image.png](image%20109.png)

![image.png](image%20110.png)

![image.png](image%20111.png)

![image.png](image%20112.png)

![image.png](image%20113.png)

![image.png](image%20114.png)

![image.png](image%20115.png)

![image.png](image%20116.png)

![image.png](image%20117.png)

![image.png](image%20118.png)

![image.png](image%20119.png)

![image.png](image%20120.png)

![image.png](image%20121.png)

![image.png](image%20122.png)

![image.png](image%20123.png)